{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMu0EnnDUr9miWtR7Q8hU5X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OlegV12/ML_in_business/blob/Lesson_3/HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FE0E1rNXU10"
      },
      "source": [
        "1. обучить несколько разных моделей на наборе данных ССЗ (train_case2.csv): логрег, бустинг, лес и т.д - на ваш выбор 2-3 варианта\n",
        "2. при обучении моделей обязательно использовать кроссвалидацию\n",
        "3. вывести сравнение полученных моделей по основным метрикам классификации: pr/rec/auc/f_score (можно в виде таблицы, где строки - модели, а столбцы - метрики)\n",
        "4. сделать выводы о том, какая модель справилась с задачей лучше других\n",
        "5. (опциональный вопрос) какая метрика (precision_recall_curve или roc_auc_curve) больше подходит в случае сильного дисбаланса классов? (когда объектов одного из классов намного больше чем другого). \n",
        "\n",
        "p.s.В вопросе проще разобраться, если вспомнить оси на графике roc auc curve и рассмотреть такой пример:\n",
        "\n",
        "Имеется 100000 объектов, из которых только 100 - класс \"1\" (99900 - класс \"0\", соответственно). \n",
        "Допустим, у нас две модели:\n",
        "\n",
        "- первая помечает 100 объектов как класс 1, но TP = 90\n",
        "- вторая помечает 1000 объектов как класс 1, но TP такой же - 90\n",
        "\n",
        "Какая модель лучше и почему? И что позволяет легче сделать вывод - roc_auc_curve или precision_recall_curve?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58FiK-13Q3t8"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bgR0fVqQ6ku",
        "outputId": "073a969f-088a-43b2-b4c3-f744c64e2147"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9KADjrmNJ6_"
      },
      "source": [
        "df = pd.read_csv('/gdrive/MyDrive/train_case2.csv', ';')"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HGQfgMrRLMW"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df.drop('cardio', 1), \n",
        "                                                    df['cardio'], random_state=0)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqKxEObKR8qq"
      },
      "source": [
        "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Transformer to select a single column from the data frame to perform additional transformations on\n",
        "    \"\"\"\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[self.key]\n",
        "    \n",
        "class NumberSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Transformer to select a single column from the data frame to perform additional transformations on\n",
        "    Use on numeric columns in the data\n",
        "    \"\"\"\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[[self.key]]\n",
        "    \n",
        "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "        self.columns = []\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = pd.get_dummies(X, prefix=self.key)\n",
        "        test_columns = [col for col in X.columns]\n",
        "        for col_ in test_columns:\n",
        "            if col_ not in self.columns:\n",
        "                X[col_] = 0\n",
        "        return X[self.columns]\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "continuos_cols = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
        "cat_cols = ['gender', 'cholesterol']\n",
        "base_cols = ['gluc', 'smoke', 'alco', 'active']\n",
        "\n",
        "continuos_transformers = []\n",
        "cat_transformers = []\n",
        "base_transformers = []\n",
        "\n",
        "for cont_col in continuos_cols:\n",
        "    transfomer =  Pipeline([\n",
        "                ('selector', NumberSelector(key=cont_col)),\n",
        "                ('standard', StandardScaler())\n",
        "            ])\n",
        "    continuos_transformers.append((cont_col, transfomer))\n",
        "    \n",
        "for cat_col in cat_cols:\n",
        "    cat_transformer = Pipeline([\n",
        "                ('selector', ColumnSelector(key=cat_col)),\n",
        "                ('ohe', OHEEncoder(key=cat_col))\n",
        "            ])\n",
        "    cat_transformers.append((cat_col, cat_transformer))\n",
        "    \n",
        "for base_col in base_cols:\n",
        "    base_transformer = Pipeline([\n",
        "                ('selector', NumberSelector(key=base_col))\n",
        "            ])\n",
        "    base_transformers.append((base_col, base_transformer))"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7W9XQIYSDAZ",
        "outputId": "471de6b2-4532-4907-8bdd-3db1f8175af9"
      },
      "source": [
        "from sklearn.pipeline import FeatureUnion\n",
        "\n",
        "feats = FeatureUnion(continuos_transformers+cat_transformers+base_transformers)\n",
        "feature_processing = Pipeline([('feats', feats)])\n",
        "\n",
        "feature_processing.fit_transform(X_train)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.73391771,  0.6873301 ,  0.74843904, ...,  1.        ,\n",
              "         0.        ,  1.        ],\n",
              "       [-1.67343538,  0.07758923, -0.29640123, ...,  0.        ,\n",
              "         0.        ,  1.        ],\n",
              "       [ 0.13738132,  1.17512278, -0.15708919, ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       ...,\n",
              "       [ 1.17775864,  1.17512278, -0.15708919, ...,  0.        ,\n",
              "         0.        ,  1.        ],\n",
              "       [-0.47190715, -1.38578883,  0.74843904, ...,  0.        ,\n",
              "         0.        ,  1.        ],\n",
              "       [ 0.38174619,  0.56538192, -0.08743318, ...,  0.        ,\n",
              "         0.        ,  1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEghCsvkSa7F",
        "outputId": "df57fb82-b25d-4037-f16b-add9795b00a4"
      },
      "source": [
        "classifier = Pipeline([\n",
        "    ('features',feats),\n",
        "    ('classifier', LogisticRegression(random_state = 42)),\n",
        "])\n",
        "\n",
        "\n",
        "#запустим кросс-валидацию\n",
        "cv_scores = cross_val_score(classifier, X_train, y_train, cv=16, scoring='roc_auc')\n",
        "cv_score = np.mean(cv_scores)\n",
        "cv_score_std = np.std(cv_scores)\n",
        "print('CV score is {}+-{}'.format(cv_score, cv_score_std))\n",
        "\n",
        "#обучим пайплайн на всем тренировочном датасете\n",
        "classifier.fit(X_train, y_train)\n",
        "y_score = classifier.predict_proba(X_test)[:, 1]"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV score is 0.7867401104915408+-0.00852135511666111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpwozG-tp9Rq"
      },
      "source": [
        "def my_metrics(y_test, y_score, cv_score, b=1,):\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test.values, y_score)\n",
        "    fscore = (1+b**2)*(precision * recall) / (b**2*precision + recall)\n",
        "    # locate the index of the largest f score\n",
        "    ix = np.argmax(fscore)\n",
        "    return (fscore[ix],\n",
        "            precision[ix],\n",
        "            recall[ix], \n",
        "            cv_score)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1Qmm0BRsV6x"
      },
      "source": [
        "lr_metrics = my_metrics(y_test, y_score, cv_score)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bwf7ZlRStfl",
        "outputId": "563f81e2-1862-4a79-eb21-9ab718ebfe85"
      },
      "source": [
        "forest = Pipeline([\n",
        "    ('features',feats),\n",
        "    ('classifier', RandomForestClassifier(max_depth=2, random_state=0,)),\n",
        "])\n",
        "\n",
        "\n",
        "#запустим кросс-валидацию\n",
        "cv_scores = cross_val_score(forest, X_train, y_train, cv=16, scoring='roc_auc')\n",
        "cv_score = np.mean(cv_scores)\n",
        "cv_score_std = np.std(cv_scores)\n",
        "print('CV score is {}+-{}'.format(cv_score, cv_score_std))\n",
        "\n",
        "#обучим пайплайн на всем тренировочном датасете\n",
        "forest.fit(X_train, y_train)\n",
        "y_score = forest.predict_proba(X_test)[:, 1]"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV score is 0.7841328301341483+-0.0073719873504775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBQVVqTts1uC"
      },
      "source": [
        "forest_metrics = my_metrics(y_test, y_score, cv_score)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoWtcfrYWR64",
        "outputId": "1a5f056d-6203-43d6-97fe-ca60d3166da8"
      },
      "source": [
        "boosting = Pipeline([\n",
        "    ('features',feats),\n",
        "    ('classifier', GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
        "max_depth=1, random_state=0)),\n",
        "])\n",
        "\n",
        "\n",
        "#запустим кросс-валидацию\n",
        "cv_scores = cross_val_score(boosting, X_train, y_train, cv=16, scoring='roc_auc')\n",
        "cv_score = np.mean(cv_scores)\n",
        "cv_score_std = np.std(cv_scores)\n",
        "print('CV score is {}+-{}'.format(cv_score, cv_score_std))\n",
        "\n",
        "#обучим пайплайн на всем тренировочном датасете\n",
        "boosting.fit(X_train, y_train)\n",
        "y_score = boosting.predict_proba(X_test)[:, 1]"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV score is 0.7971946542696801+-0.0069185562168582624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k6SshlmtEXP"
      },
      "source": [
        "boosting_metrics = (my_metrics(y_test, y_score, cv_score))"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDsXo80MtNjw"
      },
      "source": [
        "names = ['LR', 'Forest', 'Boost',]\n",
        "results = pd.DataFrame(np.array((lr_metrics, forest_metrics, boosting_metrics, )),\n",
        "columns=['f1', 'precision', 'recall', 'auc'])\n",
        "results.index = names"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "zdgZM_vQvQph",
        "outputId": "4ee5a966-d57a-4b80-f29a-d9c8538bd63f"
      },
      "source": [
        "results"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f1</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LR</th>\n",
              "      <td>0.730323</td>\n",
              "      <td>0.647431</td>\n",
              "      <td>0.837558</td>\n",
              "      <td>0.786740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Forest</th>\n",
              "      <td>0.728639</td>\n",
              "      <td>0.626055</td>\n",
              "      <td>0.871429</td>\n",
              "      <td>0.784133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Boost</th>\n",
              "      <td>0.738500</td>\n",
              "      <td>0.678503</td>\n",
              "      <td>0.810138</td>\n",
              "      <td>0.797195</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              f1  precision    recall       auc\n",
              "LR      0.730323   0.647431  0.837558  0.786740\n",
              "Forest  0.728639   0.626055  0.871429  0.784133\n",
              "Boost   0.738500   0.678503  0.810138  0.797195"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOsUWhuRw37w"
      },
      "source": [
        "В данном примере думаю лучше максимизировать recall, так что считаю, что лес справился с задачей лучше. "
      ]
    }
  ]
}